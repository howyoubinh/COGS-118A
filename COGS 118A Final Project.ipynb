{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A Final Project\n",
    "Binh Nguyen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import string\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets acquired from UCI Machine Learning Repository:\n",
    "https://archive.ics.uci.edu/ml/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. LETTER Dataset\n",
    "https://archive.ics.uci.edu/ml/datasets/letter+recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size = 20000x17\n",
    "# N = 20000\n",
    "# D = 16 features\n",
    "data_letter = np.genfromtxt('letter-recognition.data', delimiter = ',', dtype=None, encoding=None)\n",
    "n_letter = np.size(data_letter)\n",
    "d_letter = 16\n",
    "X_letter = np.zeros((n_letter,d_letter))\n",
    "\n",
    "# Create X Matrix from numpy.void type\n",
    "for i in range(n_letter):\n",
    "    for j in range(d_letter):\n",
    "        X_letter[i][j] = data_letter[i][j+1]\n",
    "        \n",
    "# Create y vector with labels for each letter\n",
    "y_letter = []\n",
    "for i in range(n_letter):\n",
    "    y_letter.append(data_letter[i][0])\n",
    "\n",
    "# Convert letters to positive and negative values\n",
    "\n",
    "# A-M as positive (+) = 1\n",
    "positive = list(string.ascii_uppercase)[0:13]\n",
    "\n",
    "# N-Z as negative (-) = 0\n",
    "negative = list(string.ascii_uppercase)[13:26]\n",
    "\n",
    "y_letter = np.asarray(y_letter)\n",
    "\n",
    "for i in range(len(y_letter)):\n",
    "    for j in range(len(positive)):\n",
    "        if y_letter[i] == positive[j]:\n",
    "            y_letter[i] = 1\n",
    "        elif y_letter[i] == negative[j]:\n",
    "            y_letter[i] = 0\n",
    "\n",
    "y_letter = y_letter.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Indian Pines dataset\n",
    "http://www.ehu.eus/ccwintco/index.php?title=Hyperspectral_Remote_Sensing_Scenes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 145 x 145 x 200 multi-dimensional array\n",
    "# 145 x 145 pixel images\n",
    "# 200 samples\n",
    "# class 11: Soybean-minmill as positive, rest as negative\n",
    "mat = sio.loadmat('Indian_pines_corrected.mat')\n",
    "values_ip = mat.values()\n",
    "X_ip = values_ip[1][0:][0:]\n",
    "\n",
    "# Load ground truth (y labels)\n",
    "mat2 = sio.loadmat('Indian_pines_gt.mat')\n",
    "values2_ip = mat2.values()\n",
    "y_ip = values2_ip[2][0:][0:]\n",
    "\n",
    "# Convert class 11 (Soybean-mintill) labels in ground truth as positive\n",
    "y_ip[y_ip[0:] == 11] = 1\n",
    "y_ip[y_ip[0:] != 1] = 0\n",
    "\n",
    "# Convert 3-D array to 2-D array\n",
    "X_ip = X_ip.transpose(2,0,1).reshape(21025, -1)\n",
    "y_ip = y_ip.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yeast dataset\n",
    "https://archive.ics.uci.edu/ml/datasets/Yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 1484 datapoints\n",
    "# d = 8 features\n",
    "data_yeast = np.genfromtxt('yeast.data.csv', delimiter = ',', dtype=None, encoding=None)\n",
    "n_yeast = np.size(data_yeast)\n",
    "d_yeast = 8\n",
    "X_yeast = np.zeros((n_yeast,d_yeast))\n",
    "\n",
    "# Create X Matrix from numpy.void type\n",
    "for i in range(n_yeast):\n",
    "    for j in range(d_yeast):\n",
    "        X_yeast[i][j] = data_yeast[i][j+1]\n",
    "        \n",
    "# Create y vector with labels for each letter\n",
    "y_yeast = []\n",
    "for i in range(n_yeast):\n",
    "    y_yeast.append(data_yeast[i][d_yeast+1])\n",
    "    \n",
    "not_nuclear = ['CYT','MIT','ME3','ME2','ME1','EXC','VAC','POX','ERL']\n",
    "\n",
    "y_yeast = np.asarray(y_yeast)\n",
    "\n",
    "for i in range(len(y_yeast)):\n",
    "    for j in range(len(not_nuclear)):\n",
    "        if y_yeast[i] == 'NUC':\n",
    "            y_yeast[i] = 1\n",
    "        elif y_yeast[i] == not_nuclear[j]:\n",
    "            y_yeast[i] = 0\n",
    "\n",
    "y_yeast = y_yeast.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(X, y, folds, test_size, model, values):\n",
    "    ''' \n",
    "    K-Fold Cross Validation:\n",
    "    values = parameters to test in 1-dimensional array\n",
    "        -e.g. values = [1, 10, 100, 100]\n",
    "    X = training data\n",
    "        -e.g X = X_letter\n",
    "    folds = k number of folds\n",
    "        -e.g. folds = 5 % for 5-fold CV\n",
    "    test_size = percent of training data to be tested\n",
    "        -e.g. test_size = 0.2 % 20% of training data as validation set\n",
    "    model = scikit.learn classifier function\n",
    "        -e.g. model= BAG_DT(values, max_samp, max_feat)\n",
    "            % For bagging decision tree\n",
    "    '''\n",
    "    n = len(X)\n",
    "    kf = KFold(n_splits = folds)\n",
    "    splits = kf.get_n_splits()\n",
    "    optimal_p = values[0]\n",
    "    count = 0\n",
    "    avg_acc = np.zeros(len(values))\n",
    "    avg_train_acc = np.zeros(len(values))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size)\n",
    "    \n",
    "    # Iterate over K-Fold cross validation\n",
    "    for i in values:\n",
    "        fold = 0\n",
    "        score_test = np.zeros(splits)\n",
    "        score_train = np.zeros(splits)\n",
    "        print \"\\np =\", i\n",
    "        \n",
    "    # Test Validation error for each fold\n",
    "        for train_idx, test_idx in kf.split(X_train):\n",
    "            fold += 1\n",
    "            X_train_set, X_test_set = X_train[train_idx], X_train[test_idx]\n",
    "            y_train_set, y_test_set = y_train[train_idx], y_train[test_idx]\n",
    "            \n",
    "            clf = model\n",
    "            clf = clf.fit(X_train_set, y_train_set)\n",
    "            \n",
    "            # Save accuracy to vector\n",
    "            score_train[fold - 1] = clf.score(X_train_set, y_train_set)\n",
    "            score_test[fold - 1] = clf.score(X_test_set, y_test_set)\n",
    "            \n",
    "        avg_train_acc[count] = np.average(score_train)\n",
    "        avg_acc[count] = np.average(score_test)\n",
    "        \n",
    "        print \"Avg training accuracy: %f\" % (avg_train_acc[count])\n",
    "        print \"Avg validation accuracy %f\" % (avg_acc[count])\n",
    "        count += 1\n",
    "    \n",
    "    index_optimal_p = avg_acc.tolist().index(max(avg_acc))\n",
    "    optimal_p = values[index_optimal_p]\n",
    "    \n",
    "    print \"\\nOptimal p:\", optimal_p\n",
    "    print \"Best validation accuracy:\", np.amax(avg_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BAG_DT(i, max_samp, max_feat):\n",
    "    clf = BaggingClassifier(\n",
    "        DecisionTreeClassifier(max_depth = i),\n",
    "            max_samples = max_samp,\n",
    "            max_features = max_feat)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "p = 1\n",
      "Avg training accuracy: 0.984375\n",
      "Avg validation accuracy 0.914187\n",
      "\n",
      "p = 10\n",
      "Avg training accuracy: 0.982500\n",
      "Avg validation accuracy 0.912625\n",
      "\n",
      "p = 100\n",
      "Avg training accuracy: 0.982812\n",
      "Avg validation accuracy 0.911188\n",
      "\n",
      "p = 1000\n",
      "Avg training accuracy: 0.985563\n",
      "Avg validation accuracy 0.916500\n",
      "\n",
      "Optimal p: 1000\n",
      "Best validation accuracy: 0.9165000000000001\n"
     ]
    }
   ],
   "source": [
    "values = [1, 10, 100, 1000]\n",
    "CV(X_letter, y_letter, 2, 0.2, BAG_DT(i, 0.5, 0.5), values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(hidden_units, i):\n",
    "    clf = MLPClassifier(hidden_units ,alpha = 1)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.2, 0.5, 0.9]\n",
      "\n",
      "p = 0\n",
      "Avg training accuracy: 0.889875\n",
      "Avg validation accuracy 0.886813\n",
      "\n",
      "p = 0.2\n",
      "Avg training accuracy: 0.893188\n",
      "Avg validation accuracy 0.888313\n",
      "\n",
      "p = 0.5\n",
      "Avg training accuracy: 0.886562\n",
      "Avg validation accuracy 0.883938\n",
      "\n",
      "p = 0.9\n",
      "Avg training accuracy: 0.885375\n",
      "Avg validation accuracy 0.879375\n",
      "\n",
      "Optimal p: 0.2\n",
      "Best validation accuracy: 0.8883125000000001\n"
     ]
    }
   ],
   "source": [
    "values = [0,0.2,0.5,0.9]\n",
    "hidden_units = [100]\n",
    "CV(X_letter, y_letter, 2, 0.2, ANN(hidden_units, i), values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
